{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6927f60-f021-4d3d-b6e1-6a5a1ef0f2aa",
   "metadata": {},
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "Rough Plan:\n",
    "- load the pre made splits\n",
    "- build the preprocessing part\n",
    "- Train different models: basic linear svm, balanced classweight, tune c, maybe nonlinear svm with rbf\n",
    "\n",
    "Very imbalanced data so using accuracy is not too helpful to gain insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a724bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d277359a-d352-4116-8c5b-50766e89994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC #computes faster (maybe change back to original to keep uniform across iterations, not sure yet)\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "053c661e-e8bf-4bc1-a905-9aa517193452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (25519, 10) y_train: (25519,)\n",
      "Train class balance: {0: 0.9894980210823308, 1: 0.010501978917669188}\n"
     ]
    }
   ],
   "source": [
    "#Loading train test val splits and getting the numeric and categorical columns\n",
    "X_train = pd.read_csv(\"../data/X_train.csv\")\n",
    "X_val   = pd.read_csv(\"../data/X_val.csv\")\n",
    "X_test  = pd.read_csv(\"../data/X_test.csv\")\n",
    "\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\").squeeze()\n",
    "y_val   = pd.read_csv(\"../data/y_val.csv\").squeeze()\n",
    "y_test  = pd.read_csv(\"../data/y_test.csv\").squeeze()\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"Train class balance:\", y_train.value_counts(normalize=True).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c645a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10, 100],\n",
    "    'svm__gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'svm__kernel': ['rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c043b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid, \n",
    "    refit=True, \n",
    "    verbose=1, \n",
    "    scoring='f1',  # optimising for f1 score\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d42d3cbd-eaf6-4392-a13c-48ee033cbf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['AMT_INCOME_TOTAL', 'DAYS_EMPLOYED', 'DAYS_BIRTH', 'CNT_FAM_MEMBERS', 'FLAG_MOBIL']\n",
      "Categorical columns: ['OCCUPATION_TYPE', 'CODE_GENDER', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE']\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = X_train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "categorical_cols = X_train.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da8d2cce-21c6-405e-9358-f4ae22022d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing with the median on numeric columns as well as sclaing\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "#Fill missing values with \"Missing\" in categorical columns + one hot encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "#Combining into one preprocessing step and transforming so they;re usable\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "441aef88-fd0d-4d72-ae2d-d8c0f3e32b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calc the metrics and return a dict\n",
    "def evaluate(model, X, y, name=\"SET\"):\n",
    "    pred = model.predict(X)\n",
    "    return {\n",
    "        \"set\": name,\n",
    "        \"accuracy\": accuracy_score(y, pred),\n",
    "        \"precision\": precision_score(y, pred, zero_division=0),\n",
    "        \"recall\": recall_score(y, pred, zero_division=0),\n",
    "        \"f1\": f1_score(y, pred, zero_division=0),\n",
    "        \"confusion_matrix\": confusion_matrix(y, pred),\n",
    "        \"report\": classification_report(y, pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "#printing the dict\n",
    "def print_eval(res):\n",
    "    print(f\"\\n {res['set']} \")\n",
    "    print(\"Accuracy :\", res[\"accuracy\"])\n",
    "    print(\"Precision:\", res[\"precision\"])\n",
    "    print(\"Recall   :\", res[\"recall\"])\n",
    "    print(\"F1       :\", res[\"f1\"])\n",
    "    print(\"Confusion matrix:\\n\", res[\"confusion_matrix\"])\n",
    "    print(\"\\nReport:\\n\", res[\"report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7c23f38-b561-4f8e-bed8-e1020c2c9f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TRAIN (v1) \n",
      "Accuracy : 0.9894980210823308\n",
      "Precision: 0.0\n",
      "Recall   : 0.0\n",
      "F1       : 0.0\n",
      "Confusion matrix:\n",
      " [[25251     0]\n",
      " [  268     0]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     25251\n",
      "           1       0.00      0.00      0.00       268\n",
      "\n",
      "    accuracy                           0.99     25519\n",
      "   macro avg       0.49      0.50      0.50     25519\n",
      "weighted avg       0.98      0.99      0.98     25519\n",
      "\n",
      "\n",
      " VAL (v1) \n",
      "Accuracy : 0.989394770524776\n",
      "Precision: 0.0\n",
      "Recall   : 0.0\n",
      "F1       : 0.0\n",
      "Confusion matrix:\n",
      " [[5411    0]\n",
      " [  58    0]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5411\n",
      "           1       0.00      0.00      0.00        58\n",
      "\n",
      "    accuracy                           0.99      5469\n",
      "   macro avg       0.49      0.50      0.50      5469\n",
      "weighted avg       0.98      0.99      0.98      5469\n",
      "\n",
      "\n",
      " TEST (v1) \n",
      "Accuracy : 0.9895776193088316\n",
      "Precision: 0.0\n",
      "Recall   : 0.0\n",
      "F1       : 0.0\n",
      "Confusion matrix:\n",
      " [[5412    0]\n",
      " [  57    0]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5412\n",
      "           1       0.00      0.00      0.00        57\n",
      "\n",
      "    accuracy                           0.99      5469\n",
      "   macro avg       0.49      0.50      0.50      5469\n",
      "weighted avg       0.98      0.99      0.98      5469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#First SVM, simplest one. It's linear and has no class weight. Shows why imbalance is a problem\n",
    "svm_v1 = Pipeline(steps=[\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"clf\", SVC(kernel=\"linear\", C=1.0))  # no class_weight yet\n",
    "])\n",
    "\n",
    "svm_v1.fit(X_train, y_train) #Training\n",
    "\n",
    "#Eval on each split and print\n",
    "res_train_v1 = evaluate(svm_v1, X_train, y_train, \"TRAIN (v1)\")\n",
    "res_val_v1   = evaluate(svm_v1, X_val, y_val, \"VAL (v1)\")\n",
    "res_test_v1  = evaluate(svm_v1, X_test, y_test, \"TEST (v1)\")\n",
    "\n",
    "print_eval(res_train_v1)\n",
    "print_eval(res_val_v1)\n",
    "print_eval(res_test_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcaa673c-ac30-42a7-9faa-ec7c38ac6ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=15000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TRAIN (v2) \n",
      "Accuracy : 0.2363337121360555\n",
      "Precision: 0.010792099368764\n",
      "Recall   : 0.7910447761194029\n",
      "F1       : 0.02129369224588188\n",
      "Confusion matrix:\n",
      " [[ 5819 19432]\n",
      " [   56   212]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.23      0.37     25251\n",
      "           1       0.01      0.79      0.02       268\n",
      "\n",
      "    accuracy                           0.24     25519\n",
      "   macro avg       0.50      0.51      0.20     25519\n",
      "weighted avg       0.98      0.24      0.37     25519\n",
      "\n",
      "\n",
      " VAL (v2) \n",
      "Accuracy : 0.2316694093984275\n",
      "Precision: 0.010396975425330813\n",
      "Recall   : 0.7586206896551724\n",
      "F1       : 0.020512820512820513\n",
      "Confusion matrix:\n",
      " [[1223 4188]\n",
      " [  14   44]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.23      0.37      5411\n",
      "           1       0.01      0.76      0.02        58\n",
      "\n",
      "    accuracy                           0.23      5469\n",
      "   macro avg       0.50      0.49      0.19      5469\n",
      "weighted avg       0.98      0.23      0.36      5469\n",
      "\n",
      "\n",
      " TEST (v2) \n",
      "Accuracy : 0.23112086304626075\n",
      "Precision: 0.009228584950307619\n",
      "Recall   : 0.6842105263157895\n",
      "F1       : 0.018211533971515294\n",
      "Confusion matrix:\n",
      " [[1225 4187]\n",
      " [  18   39]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.23      0.37      5412\n",
      "           1       0.01      0.68      0.02        57\n",
      "\n",
      "    accuracy                           0.23      5469\n",
      "   macro avg       0.50      0.46      0.19      5469\n",
      "weighted avg       0.98      0.23      0.36      5469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Second SVM, includes class_weight = \"balanced\" to help the case where high_risk = 1\n",
    "svm_v2 = Pipeline(steps=[\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"clf\", SVC(kernel=\"linear\", C=1.0, class_weight=\"balanced\", max_iter=15000, tol=1e-3)) #Has a limit to help reduce run time (remove this if you have time)\n",
    "])\n",
    "\n",
    "svm_v2.fit(X_train, y_train)\n",
    "\n",
    "res_train_v2 = evaluate(svm_v2, X_train, y_train, \"TRAIN (v2)\")\n",
    "res_val_v2   = evaluate(svm_v2, X_val, y_val, \"VAL (v2)\")\n",
    "res_test_v2  = evaluate(svm_v2, X_test, y_test, \"TEST (v2)\")\n",
    "\n",
    "print_eval(res_train_v2)\n",
    "print_eval(res_val_v2)\n",
    "print_eval(res_test_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd9c362f-2e80-4a7a-bab5-831d15be4520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.010347</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.020090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.020040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.000</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.020040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.000</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.020040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.020020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.000</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.020020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.020020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55.000</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.020020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.020020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010111</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.019646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C  val_precision  val_recall    val_f1\n",
       "2    0.100       0.010347    0.344828  0.020090\n",
       "3    1.000       0.010320    0.344828  0.020040\n",
       "4    2.000       0.010320    0.344828  0.020040\n",
       "5    3.000       0.010320    0.344828  0.020040\n",
       "1    0.010       0.010309    0.344828  0.020020\n",
       "6    7.000       0.010309    0.344828  0.020020\n",
       "7   10.000       0.010309    0.344828  0.020020\n",
       "8   55.000       0.010309    0.344828  0.020020\n",
       "9  100.000       0.010309    0.344828  0.020020\n",
       "0    0.001       0.010111    0.344828  0.019646"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Third SVM model, finding the best C. Smaller C = more regularisation, Larger C = less regularisation\n",
    "C_values = [0.001, 0.01, 0.1, 1.0,2.0,3.0,7.0, 10.0,55.0, 100.0]\n",
    "rows = []\n",
    "\n",
    "for C in C_values:\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preproc\", preprocessor),\n",
    "        #Changed to use LinearSVC since it computes much faster, change this back if need be\n",
    "        (\"clf\", LinearSVC(C=C, class_weight=\"balanced\", random_state=42, max_iter=20000))\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    pred_val = model.predict(X_val)\n",
    "    \n",
    "    #Store results into here then below we turn it into a table to view\n",
    "    rows.append({\n",
    "        \"C\": C,\n",
    "        \"val_precision\": precision_score(y_val, pred_val, zero_division=0),\n",
    "        \"val_recall\": recall_score(y_val, pred_val, zero_division=0),\n",
    "        \"val_f1\": f1_score(y_val, pred_val, zero_division=0),\n",
    "    })\n",
    "\n",
    "results_C = pd.DataFrame(rows).sort_values(\"val_f1\", ascending=False)\n",
    "results_C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53608fbb-0b25-41f2-8731-05e854c72ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C by validation F1: 0.1\n",
      "\n",
      " TEST (v3 LinearSVC tuned C) \n",
      "Accuracy : 0.631194002559883\n",
      "Precision: 0.015810276679841896\n",
      "Recall   : 0.5614035087719298\n",
      "F1       : 0.030754444978375782\n",
      "Confusion matrix:\n",
      " [[3420 1992]\n",
      " [  25   32]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.63      0.77      5412\n",
      "           1       0.02      0.56      0.03        57\n",
      "\n",
      "    accuracy                           0.63      5469\n",
      "   macro avg       0.50      0.60      0.40      5469\n",
      "weighted avg       0.98      0.63      0.76      5469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Take the best C (based on Val F1 score) and check SVMs results\n",
    "best_C = results_C.iloc[0][\"C\"]\n",
    "print(\"Best C by validation F1:\", best_C)\n",
    "\n",
    "X_train_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "svm_v3 = Pipeline(steps=[\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"clf\", LinearSVC(C=float(best_C), class_weight=\"balanced\", random_state=42, max_iter=20000))\n",
    "])\n",
    "\n",
    "svm_v3.fit(X_train_full, y_train_full)\n",
    "\n",
    "res_test_v3 = evaluate(svm_v3, X_test, y_test, \"TEST (v3 LinearSVC tuned C)\")\n",
    "\n",
    "print_eval(res_test_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bf81e65-18be-4195-8ca5-79cc703a0464",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gamma \u001b[38;5;129;01min\u001b[39;00m gamma_values:\n\u001b[1;32m      8\u001b[0m     model \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      9\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreproc\u001b[39m\u001b[38;5;124m\"\u001b[39m, preprocessor),\n\u001b[1;32m     10\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m\"\u001b[39m, SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m\"\u001b[39m, C\u001b[38;5;241m=\u001b[39mC, gamma\u001b[38;5;241m=\u001b[39mgamma, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     11\u001b[0m     ])\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     pred_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m     15\u001b[0m     rows\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m: C,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: gamma,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_pred_pos\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m((pred_val \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m     22\u001b[0m     })\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py:663\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    658\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    659\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    660\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    661\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    662\u001b[0m         )\n\u001b[0;32m--> 663\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:258\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    257\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 258\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:377\u001b[0m, in \u001b[0;36mBaseLibSVM._sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    363\u001b[0m kernel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_kernels\u001b[38;5;241m.\u001b[39mindex(kernel)\n\u001b[1;32m    365\u001b[0m libsvm_sparse\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    367\u001b[0m (\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    370\u001b[0m     dual_coef_data,\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[0;32m--> 377\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibsvm_sparse_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_weight_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_libsvm_sparse.pyx:218\u001b[0m, in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/sparse/_compressed.py:30\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy, maxprint)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_cs_matrix\u001b[39;00m(_data_matrix, _minmax_mixin, IndexMixin):\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    base array/matrix class for compressed row- and column-oriented arrays/matrices\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg1, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, maxprint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     31\u001b[0m         _data_matrix\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg1, maxprint\u001b[38;5;241m=\u001b[39mmaxprint)\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m issparse(arg1):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Fourth model is trying non-linear SVM using RBF as well as smaller list of tuning C. Maybe nonlinear performs better?\n",
    "C_values = [0.1, 1, 10]\n",
    "gamma_values = [\"scale\", 0.1, 0.01]\n",
    "\n",
    "rows = []\n",
    "for C in C_values:\n",
    "    for gamma in gamma_values:\n",
    "        model = Pipeline(steps=[\n",
    "            (\"preproc\", preprocessor),\n",
    "            (\"clf\", SVC(kernel=\"rbf\", C=C, gamma=gamma, class_weight=\"balanced\"))\n",
    "        ])\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_val = model.predict(X_val)\n",
    "\n",
    "        rows.append({\n",
    "            \"C\": C,\n",
    "            \"gamma\": gamma,\n",
    "            \"val_precision\": precision_score(y_val, pred_val, zero_division=0),\n",
    "            \"val_recall\": recall_score(y_val, pred_val, zero_division=0),\n",
    "            \"val_f1\": f1_score(y_val, pred_val, zero_division=0),\n",
    "            \"val_pred_pos\": int((pred_val == 1).sum())\n",
    "        })\n",
    "\n",
    "rbf_results = pd.DataFrame(rows).sort_values(\"val_f1\", ascending=False)\n",
    "rbf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6593db7e-0079-4074-8d1c-ac5d9eea5a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RBF params by validation F1: 10.0 scale\n",
      "\n",
      " TEST (v4 RBF, C=10.0, gamma=scale) \n",
      "Accuracy : 0.7957579082099104\n",
      "Precision: 0.027629233511586453\n",
      "Recall   : 0.543859649122807\n",
      "F1       : 0.05258693808312129\n",
      "Confusion matrix:\n",
      " [[4321 1091]\n",
      " [  26   31]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89      5412\n",
      "           1       0.03      0.54      0.05        57\n",
      "\n",
      "    accuracy                           0.80      5469\n",
      "   macro avg       0.51      0.67      0.47      5469\n",
      "weighted avg       0.98      0.80      0.88      5469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Taking the best RBF paramaters based on val F1 and returning its results\n",
    "best = rbf_results.iloc[0]\n",
    "best_C = float(best[\"C\"])\n",
    "best_gamma = best[\"gamma\"]\n",
    "\n",
    "print(\"Best RBF params by validation F1:\", best_C, best_gamma)\n",
    "\n",
    "X_train_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "svm_v4 = Pipeline(steps=[\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"clf\", SVC(kernel=\"rbf\", C=best_C, gamma=best_gamma, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "svm_v4.fit(X_train_full, y_train_full)\n",
    "\n",
    "res_test_v4 = evaluate(svm_v4, X_test, y_test, f\"TEST (v4 RBF, C={best_C}, gamma={best_gamma})\")\n",
    "print_eval(res_test_v4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc39356-ec19-47fe-a36d-059ff90aa284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM v4 (RBF tuned)</td>\n",
       "      <td>0.052587</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.027629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM v3 (LinearSVC tuned C)</td>\n",
       "      <td>0.030754</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.015810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM v2 (linear, balanced)</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.009229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM v1 (linear, no weights)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model   test_f1  test_recall  test_precision\n",
       "3           SVM v4 (RBF tuned)  0.052587     0.543860        0.027629\n",
       "2   SVM v3 (LinearSVC tuned C)  0.030754     0.561404        0.015810\n",
       "1    SVM v2 (linear, balanced)  0.018212     0.684211        0.009229\n",
       "0  SVM v1 (linear, no weights)  0.000000     0.000000        0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Little summary table to show which 'iterations' are the best performing compared to each other\n",
    "summary = pd.DataFrame([\n",
    "    {\"model\": \"SVM v1 (linear, no weights)\", \"test_f1\": res_test_v1[\"f1\"], \"test_recall\": res_test_v1[\"recall\"], \"test_precision\": res_test_v1[\"precision\"]},\n",
    "    {\"model\": \"SVM v2 (linear, balanced)\",   \"test_f1\": res_test_v2[\"f1\"], \"test_recall\": res_test_v2[\"recall\"], \"test_precision\": res_test_v2[\"precision\"]},\n",
    "    {\"model\": \"SVM v3 (LinearSVC tuned C)\",  \"test_f1\": res_test_v3[\"f1\"], \"test_recall\": res_test_v3[\"recall\"], \"test_precision\": res_test_v3[\"precision\"]},\n",
    "    {\"model\": \"SVM v4 (RBF tuned)\",          \"test_f1\": res_test_v4[\"f1\"], \"test_recall\": res_test_v4[\"recall\"], \"test_precision\": res_test_v4[\"precision\"]},\n",
    "]).sort_values(\"test_f1\", ascending=False)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12f092-d6d0-4654-8dd4-7bbb81d1437f",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Since the classes are extremely imbalanced, accuracy isn't really looked at. We look at precision, recall and F1 for the class high_risk = 1\n",
    "So the iterations\n",
    "v1 linear, with no weight class: model failed to identify any positive cases\n",
    "v2 linear, class weight is balanced: increases recall to 0.68 but precision is extremely low meaning F1 is also very low. So in other words, it caught more true positives but created a lot of false positives\n",
    "v3 tuned c: improves F1 slightly, not much change from v2\n",
    "v4 tuned RBF: best performance out of the 4, the nonlinear model seems to capture things that the linear models couldn't, but still very poor results\n",
    "Overall, decision tree and random forest models performed far better than SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c69fe-f9dd-46d3-bd05-e6f96224b726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
